import streamlit as st
import pickle
from downloads_models import download_from_config, CONFIG_FILE
from pickle_models import pickle_pytorch_models
import configparser
import argparse
import os

tokenizer, model = None, None

IDS_LABELS = {0: 'insurance',
              1: 'payments',
              2: 'investment',
              3: 'fraud',
              4: 'data analytics',
              5: 'non-fintech'}

# @st.cache(allow_output_mutation=True)
def load_model_tokenizer(model_pickle_path):
    with open(model_pickle_path, 'rb') as handle:
        tokenizer, model = pickle.load(handle)

    return tokenizer, model

def app_details():
    r"""
    Here is where title, subtitle and app description will go
    """

    # Title
    st.title('Patent classification with Transformers')
    # Subtitle
    st.subheader('Make predictions')
    # Description
    st.write('More details go here...')

    return

def run_prediciton():

    # global tokenizer, model

    st.selectbox('Choose Model', ['Bert', 'RoBerTa'])

    default_patent = """Methods and systems for managing financial data to measure the liquidity risk for a client involve, for example, 
    implementing, using a computer having a processor coupled to memory, client-defined templates for a cash flow forecasting module. Also using the computer,
    forecast data for the client may be received via the client-defined templates by the cash flow forecasting module. Likewise using the computer, a real-time 
    predictive aggregated measure of available cash flow for the client by currency by value date is generated by the cash flow forecasting module. In addition, 
    a real time measure of forecast variance is computed by the cash flow forecasting module through pseudo logic matching of the actual cash flows at transaction 
    level against the likely much higher level at which the forecasting process is operating."""

    user_input = st.text_area("Patent Text Goes Here:", default_patent)

    if st.button('Get Prediction!'):
        # label = make_prediction(model, tokenizer, text_input=user_input, ids_labels=IDS_LABELS)
        label = inference_transformer(model_pickle_path='pickled_models/distilbert-base-uncased.pickle',
                                      text_input=user_input, ids_labels=IDS_LABELS)

        st.text(label)


def make_prediction(model, tokenizer, text_input, ids_labels):
    inputs = tokenizer(text=text_input, add_special_tokens=True, truncation=True, padding=True, return_tensors='pt')

    # Forward pass, calculate logit predictions.
    # This will return the logits rather than the loss because we have
    # not provided labels.
    # token_type_ids is the same as the "segment ids", which
    # differentiates sentence 1 and 2 in 2-sentence tasks.
    # The documentation for this `model` function is here:
    # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification
    outputs = model(**inputs)

    # The call to `model` always returns a tuple, so we need to pull the
    # loss value out of the tuple along with the logits. We will use logits
    # later to to calculate training accuracy.
    logits = outputs[0]

    # Get probablities from logits
    # probs = torch.softmax(logits, dim=-1)

    # Move logits and labels to CPU
    logits = logits.detach().cpu().numpy()

    # get predicitons to list
    predict_content = logits.argmax(axis=-1).flatten().tolist()[0]

    # Predicted label
    label = ids_labels.get(predict_content, 'Unknown')

    return label


def inference_transformer(model_pickle_path, text_input, ids_labels):

    with open(model_pickle_path, 'rb') as handle:
        tokenizer, model = pickle.load(handle)
    inputs = tokenizer(text=text_input, add_special_tokens=True, truncation=True, padding=True, return_tensors='pt')

    # Forward pass, calculate logit predictions.
    # This will return the logits rather than the loss because we have
    # not provided labels.
    # token_type_ids is the same as the "segment ids", which
    # differentiates sentence 1 and 2 in 2-sentence tasks.
    # The documentation for this `model` function is here:
    # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification
    outputs = model(**inputs)

    # The call to `model` always returns a tuple, so we need to pull the
    # loss value out of the tuple along with the logits. We will use logits
    # later to to calculate training accuracy.
    logits = outputs[0]

    # Get probablities from logits
    # probs = torch.softmax(logits, dim=-1)

    # Move logits and labels to CPU
    logits = logits.detach().cpu().numpy()

    # get predicitons to list
    predict_content = logits.argmax(axis=-1).flatten().tolist()[0]

    # Predicted label
    label = ids_labels.get(predict_content, 'Unknown')

    return label


# Press the green button in the gutter to run the script.
if __name__ == '__main__':
    # Parse any input arguments
    parser = argparse.ArgumentParser(description='Description')

    # Path of modified config file
    parser.add_argument('--path_config_file', help='Path where all pretrained models are stored pickled.',
                        type=str, default='models_config.ini')

    # Path of pretrained downloaded models
    parser.add_argument('--path_models', help='Path where all pretrained models are stored pickled.',
                        type=str, default='pretrained_models')

    # Path of pickled models and tokenizers
    parser.add_argument('--model_tokenizer_pickle_path', help='Path where all pretrained models are stored pickled.',
                        type=str, default='pickled_models')

    # Parse arguments
    args = parser.parse_args()


    # Create folder if doesn't exists
    os.mkdir(args.path_models) if not os.path.isdir(args.path_models) else None

    # Create folder if doesn't exists
    os.mkdir(args.model_tokenizer_pickle_path) if not os.path.isdir(args.model_tokenizer_pickle_path) else None

    # Download all pretrained models and updated config file
    download_from_config(args.path_config_file, args.path_models)

    # Create config parser.
    config = configparser.ConfigParser()

    # Read config file from path.
    config.read(CONFIG_FILE)

    # Parse each section in the config file.
    for section in config.sections():
        # Get the Google Drive download link
        model_path = config.get(section, 'model_path', fallback='')

        # Check if file actually exists
        if os.path.isdir(model_path):
            model_tokenizer_pickle_name = pickle_pytorch_models(model_path_=model_path,
                                                                pickled_path=args.model_tokenizer_pickle_path)
            # Add pickled model path to section.
            config.set(section, 'model_tokenizer_pickle_path', model_tokenizer_pickle_name)


    # Setup app details
    app_details()

    run_prediciton()

    print(f'\nFinished running `{__file__}`!')