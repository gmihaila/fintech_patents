import streamlit as st
import pickle

tokenizer, model = None, None

IDS_LABELS = {0: 'insurance',
              1: 'payments',
              2: 'investment',
              3: 'fraud',
              4: 'data analytics',
              5: 'non-fintech'}

# @st.cache(allow_output_mutation=True)
def load_model_tokenizer(model_pickle_path):
    with open(model_pickle_path, 'rb') as handle:
        tokenizer, model = pickle.load(handle)

    return tokenizer, model

def app_details():
    r"""
    Here is where title, subtitle and app description will go
    """

    # Title
    st.title('Patent classification with Transformers')
    # Subtitle
    st.subheader('Make predictions')
    # Description
    st.write('More details go here...')

    return

def run_prediciton():

    global tokenizer, model

    st.selectbox('Choose Model', ['Bert', 'RoBerTa'])

    default_patent = """Methods and systems for managing financial data to measure the liquidity risk for a client involve, for example, 
    implementing, using a computer having a processor coupled to memory, client-defined templates for a cash flow forecasting module. Also using the computer,
    forecast data for the client may be received via the client-defined templates by the cash flow forecasting module. Likewise using the computer, a real-time 
    predictive aggregated measure of available cash flow for the client by currency by value date is generated by the cash flow forecasting module. In addition, 
    a real time measure of forecast variance is computed by the cash flow forecasting module through pseudo logic matching of the actual cash flows at transaction 
    level against the likely much higher level at which the forecasting process is operating."""

    user_input = st.text_area("Patent Text Goes Here:", default_patent)

    if st.button('Get Prediction!'):
        label = make_prediction(model, tokenizer, text_input=user_input, ids_labels=IDS_LABELS)
        # label = inference_transformer(model_pickle_path='distilbert-base-uncased.pickle',
        #                               text_input=user_input, ids_labels=IDS_LABELS)

        st.text(label)



def make_prediction(model, tokenizer, text_input, ids_labels):
    inputs = tokenizer(text=text_input, add_special_tokens=True, truncation=True, padding=True, return_tensors='pt')

    # Forward pass, calculate logit predictions.
    # This will return the logits rather than the loss because we have
    # not provided labels.
    # token_type_ids is the same as the "segment ids", which
    # differentiates sentence 1 and 2 in 2-sentence tasks.
    # The documentation for this `model` function is here:
    # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification
    outputs = model(**inputs)

    # The call to `model` always returns a tuple, so we need to pull the
    # loss value out of the tuple along with the logits. We will use logits
    # later to to calculate training accuracy.
    logits = outputs[0]

    # Get probablities from logits
    # probs = torch.softmax(logits, dim=-1)

    # Move logits and labels to CPU
    logits = logits.detach().cpu().numpy()

    # get predicitons to list
    predict_content = logits.argmax(axis=-1).flatten().tolist()[0]

    # Predicted label
    label = ids_labels.get(predict_content, 'Unknown')

    return label


# Press the green button in the gutter to run the script.
if __name__ == '__main__':

    tokenizer, model = load_model_tokenizer('distilbert-base-uncased.pickle')

    # Setup app details
    app_details()

    run_prediciton()